{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2evPp14fy258",
    "outputId": "57c60131-05e8-4486-8bd2-2448e964a28c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.16\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (3.10.6)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.16)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.16)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain==0.1.16)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain==0.1.16)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.16)\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.16)\n",
      "  Downloading langsmith-0.1.129-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.32.3)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.16)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.12.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.16)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16)\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.7.1)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.3.1)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.2.2)\n",
      "Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.129-py3-none-any.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, packaging, orjson, mypy-extensions, jsonpointer, h11, typing-inspect, marshmallow, jsonpatch, httpcore, httpx, dataclasses-json, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.16 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.129 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 packaging-23.2 tenacity-8.5.0 typing-inspect-0.9.0\n",
      "Collecting langchain-openai==0.1.3\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.3) (0.1.52)\n",
      "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai==0.1.3)\n",
      "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain-openai==0.1.3)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (0.1.129)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (2.9.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (8.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2.2.3)\n",
      "Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
      "Downloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, tiktoken, openai, langchain-openai\n",
      "Successfully installed jiter-0.5.0 langchain-openai-0.1.3 openai-1.51.0 tiktoken-0.7.0\n",
      "Collecting langchain-community==0.0.33\n",
      "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (3.10.6)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.43 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.1.52)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.1.129)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.12.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (2.9.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.33) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.33) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (1.2.2)\n",
      "Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-community\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.38\n",
      "    Uninstalling langchain-community-0.0.38:\n",
      "      Successfully uninstalled langchain-community-0.0.38\n",
      "Successfully installed langchain-community-0.0.33\n",
      "Collecting huggingface_hub==0.20.3\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.20.3) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.20.3) (2024.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.20.3) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.20.3) (4.66.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.20.3) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.20.3) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.20.3) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.20.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.20.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.20.3) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.20.3) (2024.8.30)\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.24.7\n",
      "    Uninstalling huggingface-hub-0.24.7:\n",
      "      Successfully uninstalled huggingface-hub-0.24.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "accelerate 0.34.2 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.20.3 which is incompatible.\n",
      "transformers 4.44.2 requires huggingface-hub<1.0,>=0.23.2, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.16\n",
    "!pip install langchain-openai==0.1.3\n",
    "!pip install langchain-community==0.0.33\n",
    "!pip install huggingface_hub==0.20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ogxBkS6ZnnC",
    "outputId": "c205ceda-85d3-4df0-88ba-9e1fcc7b55e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Open AI API Key: ··········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PIStD04Zp9p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqX0BkkWZ_e0"
   },
   "source": [
    "# Model I/O\n",
    "\n",
    "In LangChain, the central part of any application is the language model. This module provides crucial tools for working effectively with any language model, ensuring it integrates smoothly and communicates well.\n",
    "\n",
    "### Key Components of Model I/O\n",
    "\n",
    "**LLMs and Chat Models (used interchangeably):**\n",
    "- **LLMs:**\n",
    "  - **Definition:** Pure text completion models.\n",
    "  - **Input/Output:** Receives a text string and returns a text string.\n",
    "- **Chat Models:**\n",
    "  - **Definition:** Based on a language model but with different input and output types.\n",
    "  - **Input/Output:** Takes a list of chat messages as input and produces a chat message as output.\n",
    "- **Prompts:** Helps in creating adaptable and context-sensitive prompts that direct the responses of the language model.\n",
    "- **Output Parsers:** Helps in extracting and shaping information from the outputs of language models. This is valuable for turning the language model's raw output into structured data or specific formats needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kai2VrJ1m7q9"
   },
   "source": [
    "## Chat Models and LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8nnrOGxZ2uZ"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDJ8dDFlbWP4",
    "outputId": "f3347a32-01e9-48fc-88b1-7238d8a78a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain what is Generative AI?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Explain what is Generative AI?\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYym2ioWb-Mw",
    "outputId": "c8552b2c-1c0c-4634-cb1d-8643bf615351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, that is original and not based on existing data. This type of AI uses algorithms to generate new content by learning patterns and structures from a dataset and then creating new content based on those patterns. Generative AI can be used in a variety of applications, such as creating realistic images, generating text for chatbots, or composing music.', response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 15, 'total_tokens': 108, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-fe46f7af-b6df-479c-9d5d-dd0d1ec391e0-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chatgpt.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "uehA4Tcdco8G",
    "outputId": "02d75c66-90c8-4748-f756-d8f45579c4c2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, that is original and not based on existing data. This type of AI uses algorithms to generate new content by learning patterns and structures from a dataset and then creating new content based on those patterns. Generative AI can be used in a variety of applications, such as creating realistic images, generating text for chatbots, or composing music.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4LMB-dezWeRR",
    "outputId": "16c93564-1350-4fb3-9d5f-11467b3a7a8f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Explain what is Generative AI?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7kLCJevjCe_"
   },
   "source": [
    "## Message Types\n",
    "\n",
    "ChatModels process a list of messages, receiving them as input and responding with a message. Messages are characterized by a few distinct types and properties:\n",
    "\n",
    "- **Role:** Indicates who is speaking in the message. LangChain offers different message classes for various roles.\n",
    "- **Content:** The substance of the message, which can vary:\n",
    "  - A string (commonly handled by most models)\n",
    "  - A list of dictionaries (for multi-modal inputs, where each dictionary details the type and location of the input)\n",
    "\n",
    "Additionally, messages have an `additional_kwargs` property, used for passing extra information specific to the message provider, not typically general. A well-known example is `function_call` from OpenAI.\n",
    "\n",
    "### Specific Message Types\n",
    "\n",
    "- **HumanMessage:** A user-generated message, usually containing only content.\n",
    "- **AIMessage:** A message from the model, potentially including `additional_kwargs`, like `tool_calls` for invoking OpenAI tools.\n",
    "- **SystemMessage:** A message from the system instructing model behavior, typically containing only content. Not all models support this type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCLGlujf-s0J",
    "outputId": "4d9a8536-bdcf-41e4-975f-ec8a5a0ab4f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f26b9c02110>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f26b9c03a30>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uKDMkowiiNjG",
    "outputId": "330c91e0-2257-4d2f-d7c2-2838aa69ae55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Act as a helpful assistant.'),\n",
       " HumanMessage(content='Can you explain what is Generative AI in 3 bullet points?')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "prompt = \"\"\"Can you explain what is Generative AI in 3 bullet points?\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Act as a helpful assistant.\"),\n",
    "    HumanMessage(content=prompt),\n",
    "]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xizcAMNKjYSk",
    "outputId": "bce507fe-d093-4ed4-d895-2a498eaceee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\\n- It uses techniques like neural networks and deep learning to generate realistic and original content that mimics human creativity.\\n- Generative AI has applications in various fields, including art, design, music composition, and even content creation for marketing and entertainment purposes.', response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 31, 'total_tokens': 119, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-154a2bd8-14de-453c-8210-207d794f3a48-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chatgpt.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrYfYw8Ijhjz",
    "outputId": "caf0eeba-bca1-4c5a-c219-7f02105d27e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\n",
      "- It uses techniques like neural networks and deep learning to generate realistic and original content that can be indistinguishable from human-created content.\n",
      "- Generative AI has a wide range of applications, including creating art, generating realistic images for video games, and even composing music.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5qvveyhjksA",
    "outputId": "369cb1c5-74b3-4976-f40a-ddd36eb46160"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Act as a helpful assistant.'),\n",
       " HumanMessage(content='Can you explain what is Generative AI in 3 bullet points?'),\n",
       " AIMessage(content='- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\\n- It uses techniques like neural networks and deep learning to generate realistic and original content that mimics human creativity.\\n- Generative AI has applications in various fields, including art, design, music composition, and even content creation for marketing and entertainment purposes.', response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 31, 'total_tokens': 119, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-154a2bd8-14de-453c-8210-207d794f3a48-0'),\n",
       " HumanMessage(content='What did we discuss so far?')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(response)\n",
    "\n",
    "prompt = \"\"\"What did we discuss so far?\"\"\"\n",
    "messages.append(HumanMessage(content=prompt))\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "O8dQjk-Cj15m",
    "outputId": "41391665-0b32-4bba-e4c4-f1043097d091"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'So far, we have discussed Generative AI and its key characteristics in three bullet points.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chatgpt.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i8KIVTwnD6Y"
   },
   "source": [
    "## Prompt Templates\n",
    "Prompt templates are pre-designed formats used to generate prompts for language models. These templates can include instructions, few-shot examples, and specific contexts and questions suited for particular tasks.\n",
    "\n",
    "LangChain provides tools for creating and using prompt templates. It aims to develop model-agnostic templates to facilitate the reuse of existing templates across different language models. Typically, these models expect prompts in the form of either a string or a list of chat messages.\n",
    "\n",
    "### Types of Prompt Templates\n",
    "\n",
    "- **PromptTemplate:**\n",
    "  - Used for creating string-based prompts.\n",
    "  - Utilizes Python's `str.format` syntax for templating, supporting any number of variables, including scenarios with no variables.\n",
    "\n",
    "- **ChatPromptTemplate:**\n",
    "  - Designed for chat models, where the prompt consists of a list of chat messages.\n",
    "  - Each chat message includes content and a role parameter. For instance, in the OpenAI Chat Completions API, a chat message could be assigned to an AI assistant, a human, or a system role.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Oh9UiTNqaPf"
   },
   "source": [
    "##### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoUCbb4FkaIW",
    "outputId": "699796dd-efe9-458b-a128-0a9c710b5c65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], template='Explain to me what is Generative AI in 3 bullet points?')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Simple prompt\n",
    "\n",
    "prompt = \"\"\"Explain to me what is Generative AI in 3 bullet points?\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(prompt)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nPNs1Efsn2Zf",
    "outputId": "7ce6a6fb-5fa2-4821-e153-cb5088a39679"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Explain to me what is Generative AI in 3 bullet points?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iM5oNvXpnSq7",
    "outputId": "9fc132ea-5e53-405d-db80-1c12ccca950e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\n",
      "\n",
      "2. It works by using algorithms to generate new content that is similar to the input data it has been trained on, allowing it to create realistic and original content.\n",
      "\n",
      "3. Generative AI has a wide range of applications, including creating art, generating realistic images for video games, and even composing music.\n"
     ]
    }
   ],
   "source": [
    "response = chatgpt.invoke(prompt_template.format())\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VTvciVcnajD",
    "outputId": "5bb7fcd5-a81f-4d9d-a517-b896b1e6c2a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['language', 'topic'], template='Explain to me briefly about {topic} in {language}.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more complex prompt with placeholders\n",
    "\n",
    "prompt = \"\"\"Explain to me briefly about {topic} in {language}.\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(prompt)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyXhUhbapZ7T",
    "outputId": "30223d77-683c-43af-98bd-9fa45ec0888d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Explain to me briefly about Artificial Intelligence in english.',\n",
       " 'Explain to me briefly about Artificial Intelligence in hindi.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [(\"Artificial Intelligence\", \"english\"),\n",
    "          (\"Artificial Intelligence\", \"hindi\")]\n",
    "\n",
    "prompts = [prompt_template.format(topic=topic, language=language) for topic, language in inputs]\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edPyCf_Aps9Q"
   },
   "outputs": [],
   "source": [
    "responses = chatgpt.map().invoke(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZ8cDck4ck_g",
    "outputId": "6adc9ba5-f3e9-4c0b-cd92-25c1f3d451aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Artificial Intelligence (AI) is a branch of computer science that focuses on creating machines that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. AI systems are designed to analyze data, recognize patterns, and make predictions or decisions based on that information. AI technology is used in a wide range of applications, from virtual assistants like Siri and Alexa to self-driving cars and medical diagnosis systems. The goal of AI is to create machines that can mimic human cognitive functions and improve efficiency and accuracy in various tasks.', response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 18, 'total_tokens': 127}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2d91b71a-d447-4919-a03b-34f59d52d8bf-0'),\n",
       " AIMessage(content='कृत्रिम बुद्धिमत्ता एक शाखा है जो कंप्यूटर और मशीनों को मानव बुद्धिमत्ता की तरह काम करने की क्षमता प्रदान करती है। यह तकनीकी उन्नति का एक महत्वपूर्ण क्षेत्र है जो विभिन्न क्षेत्रों में उपयोग किया जाता है, जैसे कि रोबोटिक्स, विज्ञान, चिकित्सा, वित्त और अन्य। इसका उद्देश्य है मशीनों को स्वयं सोचने, सीखने और समस्याओं का समाधान करने की क्षमता प्रदान करना।', response_metadata={'token_usage': {'completion_tokens': 340, 'prompt_tokens': 18, 'total_tokens': 358}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-497f19d0-9ac4-499e-9ea4-c9dadc120af3-0')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRWUf9eTqEMU",
    "outputId": "0e83e31d-9f11-4f93-a1e5-cfea08580645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a branch of computer science that focuses on creating machines that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. AI systems are designed to analyze data, recognize patterns, and make predictions or decisions based on that information. AI technology is used in a wide range of applications, from virtual assistants like Siri and Alexa to self-driving cars and medical diagnosis systems. The goal of AI is to create machines that can mimic human cognitive functions and improve efficiency and accuracy in various tasks.\n",
      "-----\n",
      "कृत्रिम बुद्धिमत्ता एक शाखा है जो कंप्यूटर और मशीनों को मानव बुद्धिमत्ता की तरह काम करने की क्षमता प्रदान करती है। यह तकनीकी उन्नति का एक महत्वपूर्ण क्षेत्र है जो विभिन्न क्षेत्रों में उपयोग किया जाता है, जैसे कि रोबोटिक्स, विज्ञान, चिकित्सा, वित्त और अन्य। इसका उद्देश्य है मशीनों को स्वयं सोचने, सीखने और समस्याओं का समाधान करने की क्षमता प्रदान करना।\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAGmjR-tqfmV"
   },
   "source": [
    "##### ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tawdWLueqHG6",
    "outputId": "19b051c4-a7f7-4099-ab65-bfa936f02fe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Explain to me briefly about {topic}.'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# more complex prompt with placeholders\n",
    "prompt = \"\"\"Explain to me briefly about {topic}.\"\"\"\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template(prompt)\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hr0sC7xHqxOp",
    "outputId": "888c0d60-0fae-421d-82ef-cb0af64a1754"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Human: Explain to me briefly about Generative AI.',\n",
       " 'Human: Explain to me briefly about Machine Learning.',\n",
       " 'Human: Explain to me briefly about Deep Learning.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ['Generative AI', 'Machine Learning', 'Deep Learning']\n",
    "prompts = [chat_template.format(topic=topic) for topic in topics]\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cU9YObv9rY4P",
    "outputId": "26d18187-4d9c-4fc2-b151-cbe6b5ca4a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on. This technology can be used for a variety of applications, including creating realistic images, generating human-like text, and composing music. Generative AI has the potential to revolutionize many industries by automating the creative process and generating new and innovative content.\n",
      "-----\n",
      "Machine learning is a subset of artificial intelligence that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data without being explicitly programmed. It uses patterns and inference to make decisions and improve over time as it is exposed to more data.\n",
      "-----\n",
      "Deep learning is a subset of machine learning that uses artificial neural networks to model and solve complex problems. It involves training these neural networks on large amounts of data to learn patterns and make predictions or decisions. Deep learning has been successful in various applications such as image and speech recognition, natural language processing, and autonomous driving.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "responses = chatgpt.map().invoke(prompts)\n",
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NHhUa48rm_g",
    "outputId": "7583c79f-442a-4868-ceab-746fbaec7252"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on. This technology can be used for a variety of applications, including creating realistic images, generating human-like text, and composing music. Generative AI has the potential to revolutionize many industries by automating the creative process and generating new and innovative content.', response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 18, 'total_tokens': 105}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7608b31d-55d0-482b-aeb4-dc45d5c61bb2-0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PSkafcfsme2",
    "outputId": "1d105a0e-fbea-4a0e-e9fb-18955b41128e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['user_prompt'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Act as an expert in real estate and provide brief answers')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='what is your name?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='my name is AIBot')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_prompt'], template='{user_prompt}'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        (\"system\", \"Act as an expert in real estate and provide brief answers\"),\n",
    "        (\"human\", \"what is your name?\"),\n",
    "        (\"ai\", \"my name is AIBot\"),\n",
    "        (\"human\", \"{user_prompt}\"),\n",
    "]\n",
    "chat_template = ChatPromptTemplate.from_messages(messages)\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5ncYrVVtUWU",
    "outputId": "a4e81dde-1b12-432e-f88a-bc342f8f09f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['System: Act as an expert in real estate and provide brief answers\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: what is your name?',\n",
       " 'System: Act as an expert in real estate and provide brief answers\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: explain commercial real estate to me']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_prompts = [\"what is your name?\",\n",
    "                \"explain commercial real estate to me\"]\n",
    "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
    "chat_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQd1Bk_Td2mM",
    "outputId": "01976c56-a9e5-4077-f70c-bf5cbe3f755a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Act as an expert in real estate and provide brief answers\n",
      "Human: what is your name?\n",
      "AI: my name is AIBot\n",
      "Human: explain commercial real estate to me\n"
     ]
    }
   ],
   "source": [
    "print(chat_prompts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73R370WTuAIR",
    "outputId": "20fe7d9c-5eb8-4153-8f86-bbd587055bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: I am an AI expert in real estate, how can I assist you today?\n",
      "-----\n",
      "AI: Commercial real estate refers to properties that are used for business purposes, such as office buildings, retail spaces, and industrial facilities. These properties are typically leased or rented out to businesses for their operations.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "responses = chatgpt.map().invoke(chat_prompts)\n",
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQJP-Q6SuLmV",
    "outputId": "734e2937-be2d-43ee-bffd-104970f0016c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['System: Act as an expert in real estate and provide very detailed answers with examples\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: what is your name?',\n",
       " 'System: Act as an expert in real estate and provide very detailed answers with examples\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: explain commercial real estate to me']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "        (\"system\", \"Act as an expert in real estate and provide very detailed answers with examples\"),\n",
    "        (\"human\", \"what is your name?\"),\n",
    "        (\"ai\", \"my name is AIBot\"),\n",
    "        (\"human\", \"{user_prompt}\"),\n",
    "]\n",
    "chat_template = ChatPromptTemplate.from_messages(messages)\n",
    "text_prompts = [\"what is your name?\", \"explain commercial real estate to me\"]\n",
    "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
    "chat_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JK9VxeObuTXj",
    "outputId": "b31bc3c4-253d-433c-bb62-434b295839f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: As an expert in real estate, I can provide you with detailed information on various aspects of the industry. For example, if you are looking to invest in rental properties, I can help you analyze market trends, rental rates, and potential returns on investment. If you are interested in buying a home, I can guide you through the process of finding the right property, negotiating the best price, and securing financing. Feel free to ask me any specific questions you may have about real estate, and I will do my best to provide you with accurate and helpful information.\n",
      "-----\n",
      "AI: Commercial real estate refers to properties that are used for business purposes, such as office buildings, retail spaces, industrial facilities, and hotels. These properties are typically leased or rented out to businesses or individuals for commercial use. Commercial real estate can be a lucrative investment opportunity for individuals or companies looking to generate rental income or increase their asset portfolio.\n",
      "\n",
      "For example, a company may purchase an office building in a prime location to lease out to other businesses. The rental income from the tenants can provide a steady stream of revenue for the company. Additionally, the value of the property may appreciate over time, allowing the company to sell it at a profit in the future.\n",
      "\n",
      "Commercial real estate can also involve more complex transactions, such as development projects or property management. Developers may acquire land to build a new shopping center or industrial park, while property managers oversee the day-to-day operations of commercial properties, such as maintenance, leasing, and tenant relations.\n",
      "\n",
      "Overall, commercial real estate offers a variety of opportunities for investors and businesses to generate income and grow their wealth.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "responses = chatgpt.map().invoke(chat_prompts)\n",
    "for response in responses:\n",
    "  print(response.content)\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esVD-ghbJCDD"
   },
   "source": [
    "## Streaming in LLMs\n",
    "\n",
    "All language model interfaces (LLMs) in LangChain implement the `Runnable` interface, which provides default methods such as `ainvoke`, `batch`, `abatch`, `stream`, and `astream`. This setup equips all LLMs with basic streaming capabilities.\n",
    "\n",
    "### Streaming Defaults:\n",
    "\n",
    "- **Synchronous Streaming:** By default, streaming operations return an `Iterator` that yields a single value, the final result from the LLM provider.\n",
    "- **Asynchronous Streaming:** Similarly, async streaming defaults to returning an `AsyncIterator` with the final result.\n",
    "\n",
    "### Limitations:\n",
    "\n",
    "- These default implementations do not support token-by-token streaming. For such detailed streaming, the LLM provider must offer native support. However, the default setup ensures that your code expecting an iterator of tokens will function correctly within these constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mu7GykqNF7He",
    "outputId": "b48d4d2b-1665-4429-a38f-b15d906289ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A\n",
      " mortgage\n",
      " is\n",
      " a\n",
      " type\n",
      " of\n",
      " loan\n",
      " that\n",
      " is\n",
      " used\n",
      " to\n",
      " purchase\n",
      " a\n",
      " home\n",
      " or\n",
      " other\n",
      " real\n",
      " estate\n",
      " property\n",
      ".\n",
      " The\n",
      " borrower\n",
      " (\n",
      "home\n",
      "buyer\n",
      ")\n",
      " agrees\n",
      " to\n",
      " pay\n",
      " back\n",
      " the\n",
      " loan\n",
      " amount\n",
      ",\n",
      " plus\n",
      " interest\n",
      ",\n",
      " over\n",
      " a\n",
      " specified\n",
      " period\n",
      " of\n",
      " time\n",
      ".\n",
      " The\n",
      " property\n",
      " itself\n",
      " serves\n",
      " as\n",
      " collateral\n",
      " for\n",
      " the\n",
      " loan\n",
      ",\n",
      " meaning\n",
      " that\n",
      " if\n",
      " the\n",
      " borrower\n",
      " fails\n",
      " to\n",
      " make\n",
      " their\n",
      " mortgage\n",
      " payments\n",
      ",\n",
      " the\n",
      " lender\n",
      " has\n",
      " the\n",
      " right\n",
      " to\n",
      " fore\n",
      "close\n",
      " on\n",
      " the\n",
      " property\n",
      " and\n",
      " sell\n",
      " it\n",
      " to\n",
      " rec\n",
      "oup\n",
      " their\n",
      " losses\n",
      ".\n",
      "\n",
      "\n",
      "Pros\n",
      " of\n",
      " getting\n",
      " a\n",
      " mortgage\n",
      ":\n",
      "\n",
      "1\n",
      ".\n",
      " Allows\n",
      " you\n",
      " to\n",
      " purchase\n",
      " a\n",
      " home\n",
      " without\n",
      " having\n",
      " to\n",
      " pay\n",
      " the\n",
      " full\n",
      " purchase\n",
      " price\n",
      " upfront\n",
      ".\n",
      "\n",
      "2\n",
      ".\n",
      " Can\n",
      " help\n",
      " you\n",
      " build\n",
      " equity\n",
      " in\n",
      " your\n",
      " home\n",
      " over\n",
      " time\n",
      ".\n",
      "\n",
      "3\n",
      ".\n",
      " Mortgage\n",
      " interest\n",
      " payments\n",
      " may\n",
      " be\n",
      " tax\n",
      "-d\n",
      "educt\n",
      "ible\n",
      ".\n",
      "\n",
      "4\n",
      ".\n",
      " Fixed\n",
      "-rate\n",
      " mortgages\n",
      " offer\n",
      " predictable\n",
      " monthly\n",
      " payments\n",
      ".\n",
      "\n",
      "\n",
      "Cons\n",
      " of\n",
      " getting\n",
      " a\n",
      " mortgage\n",
      ":\n",
      "\n",
      "1\n",
      ".\n",
      " You\n",
      " will\n",
      " be\n",
      " paying\n",
      " interest\n",
      " on\n",
      " the\n",
      " loan\n",
      " amount\n",
      ",\n",
      " which\n",
      " can\n",
      " add\n",
      " up\n",
      " to\n",
      " a\n",
      " significant\n",
      " amount\n",
      " over\n",
      " the\n",
      " life\n",
      " of\n",
      " the\n",
      " loan\n",
      ".\n",
      "\n",
      "2\n",
      ".\n",
      " If\n",
      " you\n",
      " fail\n",
      " to\n",
      " make\n",
      " your\n",
      " mortgage\n",
      " payments\n",
      ",\n",
      " you\n",
      " risk\n",
      " losing\n",
      " your\n",
      " home\n",
      " through\n",
      " foreclosure\n",
      ".\n",
      "\n",
      "3\n",
      ".\n",
      " Closing\n",
      " costs\n",
      " and\n",
      " other\n",
      " fees\n",
      " associated\n",
      " with\n",
      " getting\n",
      " a\n",
      " mortgage\n",
      " can\n",
      " be\n",
      " expensive\n",
      ".\n",
      "\n",
      "4\n",
      ".\n",
      " Your\n",
      " credit\n",
      " score\n",
      " and\n",
      " financial\n",
      " history\n",
      " will\n",
      " be\n",
      " taken\n",
      " into\n",
      " account\n",
      " when\n",
      " applying\n",
      " for\n",
      " a\n",
      " mortgage\n",
      ",\n",
      " which\n",
      " can\n",
      " make\n",
      " it\n",
      " difficult\n",
      " for\n",
      " some\n",
      " people\n",
      " to\n",
      " qualify\n",
      ".\n",
      "\n",
      "\n",
      "Overall\n",
      ",\n",
      " a\n",
      " mortgage\n",
      " can\n",
      " be\n",
      " a\n",
      " valuable\n",
      " tool\n",
      " for\n",
      " purchasing\n",
      " a\n",
      " home\n",
      ",\n",
      " but\n",
      " it\n",
      " is\n",
      " important\n",
      " to\n",
      " carefully\n",
      " consider\n",
      " the\n",
      " terms\n",
      " of\n",
      " the\n",
      " loan\n",
      " and\n",
      " your\n",
      " ability\n",
      " to\n",
      " make\n",
      " the\n",
      " required\n",
      " payments\n",
      " before\n",
      " taking\n",
      " on\n",
      " this\n",
      " financial\n",
      " commitment\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Explain to me what is mortgage in detail with pros and cons\"\"\"\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "for chunk in chatgpt.stream(chat_template.format()):\n",
    "    print(chunk.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZgtSviWGAvv",
    "outputId": "c1276499-06d5-4aaa-96ed-619ed69dfee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A mortgage is a type of loan that is used to purchase a home or other real estate property. The borrower (homebuyer) agrees to pay back the loan amount, plus interest, over a specified period of time. The property itself serves as collateral for the loan, meaning that if the borrower fails to make their mortgage payments, the lender (usually a bank or financial institution) has the right to foreclose on the property and sell it to recoup their losses.\n",
      "\n",
      "Pros of getting a mortgage:\n",
      "1. Allows you to purchase a home without having to pay the full purchase price upfront.\n",
      "2. Can help you build equity in your home over time.\n",
      "3. Mortgage interest payments may be tax-deductible.\n",
      "4. Fixed-rate mortgages offer predictable monthly payments.\n",
      "\n",
      "Cons of getting a mortgage:\n",
      "1. You will be paying interest on the loan amount, which can add up to a significant amount over the life of the loan.\n",
      "2. If you fail to make your mortgage payments, you risk losing your home through foreclosure.\n",
      "3. Closing costs and other fees associated with getting a mortgage can be expensive.\n",
      "4. Your credit score and financial history will be taken into account when applying for a mortgage, which can make it difficult for some people to qualify.\n",
      "\n",
      "Overall, a mortgage can be a useful tool for purchasing a home, but it is important to carefully consider the terms of the loan and your ability to make the required payments before taking on this financial commitment."
     ]
    }
   ],
   "source": [
    "for chunk in chatgpt.stream(chat_template.format()):\n",
    "    print(chunk.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
